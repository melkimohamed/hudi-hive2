<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="fr"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../jacoco-resources/report.gif" type="image/gif"/><title>HoodieLogBlock.java</title><link rel="stylesheet" href="../../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../../index.html" class="el_report">hudi-spark-bundle_2.11</a> &gt; <a href="../index.html" class="el_bundle">hudi-common</a> &gt; <a href="index.source.html" class="el_package">org.apache.hudi.common.table.log.block</a> &gt; <span class="el_source">HoodieLogBlock.java</span></div><h1>HoodieLogBlock.java</h1><pre class="source lang-java linenums">/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.hudi.common.table.log.block;

import org.apache.hudi.common.model.HoodieLogFile;
import org.apache.hudi.common.table.log.HoodieMergedLogRecordScanner;
import org.apache.hudi.common.util.FSUtils;
import org.apache.hudi.common.util.Option;
import org.apache.hudi.exception.HoodieException;
import org.apache.hudi.exception.HoodieIOException;

import org.apache.hadoop.fs.FSDataInputStream;

import javax.annotation.Nonnull;

import java.io.ByteArrayOutputStream;
import java.io.DataInputStream;
import java.io.DataOutputStream;
import java.io.EOFException;
import java.io.IOException;
import java.util.HashMap;
import java.util.Map;

/**
 * Abstract class defining a block in HoodieLogFile.
 */
public abstract class HoodieLogBlock {

  /**
   * The current version of the log block. Anytime the logBlock format changes this version needs to be bumped and
   * corresponding changes need to be made to {@link HoodieLogBlockVersion} TODO : Change this to a class, something
   * like HoodieLogBlockVersionV1/V2 and implement/override operations there
   */
<span class="nc" id="L50">  public static int version = 1;</span>
  // Header for each log block
  private final Map&lt;HeaderMetadataType, String&gt; logBlockHeader;
  // Footer for each log block
  private final Map&lt;HeaderMetadataType, String&gt; logBlockFooter;
  // Location of a log block on disk
  private final Option&lt;HoodieLogBlockContentLocation&gt; blockContentLocation;
  // data for a specific block
  private Option&lt;byte[]&gt; content;
  // TODO : change this to just InputStream so this works for any FileSystem
  // create handlers to return specific type of inputstream based on FS
  // input stream corresponding to the log file where this logBlock belongs
  protected FSDataInputStream inputStream;
  // Toggle flag, whether to read blocks lazily (I/O intensive) or not (Memory intensive)
  protected boolean readBlockLazily;

  public HoodieLogBlock(@Nonnull Map&lt;HeaderMetadataType, String&gt; logBlockHeader,
      @Nonnull Map&lt;HeaderMetadataType, String&gt; logBlockFooter,
      @Nonnull Option&lt;HoodieLogBlockContentLocation&gt; blockContentLocation, @Nonnull Option&lt;byte[]&gt; content,
<span class="nc" id="L69">      FSDataInputStream inputStream, boolean readBlockLazily) {</span>
<span class="nc" id="L70">    this.logBlockHeader = logBlockHeader;</span>
<span class="nc" id="L71">    this.logBlockFooter = logBlockFooter;</span>
<span class="nc" id="L72">    this.blockContentLocation = blockContentLocation;</span>
<span class="nc" id="L73">    this.content = content;</span>
<span class="nc" id="L74">    this.inputStream = inputStream;</span>
<span class="nc" id="L75">    this.readBlockLazily = readBlockLazily;</span>
<span class="nc" id="L76">  }</span>

  // Return the bytes representation of the data belonging to a LogBlock
  public byte[] getContentBytes() throws IOException {
<span class="nc" id="L80">    throw new HoodieException(&quot;No implementation was provided&quot;);</span>
  }

  public byte[] getMagic() {
<span class="nc" id="L84">    throw new HoodieException(&quot;No implementation was provided&quot;);</span>
  }

  public HoodieLogBlockType getBlockType() {
<span class="nc" id="L88">    throw new HoodieException(&quot;No implementation was provided&quot;);</span>
  }

  public long getLogBlockLength() {
<span class="nc" id="L92">    throw new HoodieException(&quot;No implementation was provided&quot;);</span>
  }

  public Option&lt;HoodieLogBlockContentLocation&gt; getBlockContentLocation() {
<span class="nc" id="L96">    return this.blockContentLocation;</span>
  }

  public Map&lt;HeaderMetadataType, String&gt; getLogBlockHeader() {
<span class="nc" id="L100">    return logBlockHeader;</span>
  }

  public Map&lt;HeaderMetadataType, String&gt; getLogBlockFooter() {
<span class="nc" id="L104">    return logBlockFooter;</span>
  }

  public Option&lt;byte[]&gt; getContent() {
<span class="nc" id="L108">    return content;</span>
  }

  /**
   * Type of the log block WARNING: This enum is serialized as the ordinal. Only add new enums at the end.
   */
<span class="nc" id="L114">  public enum HoodieLogBlockType {</span>
<span class="nc" id="L115">    COMMAND_BLOCK, DELETE_BLOCK, CORRUPT_BLOCK, AVRO_DATA_BLOCK</span>
  }

  /**
   * Log Metadata headers abstraction for a HoodieLogBlock WARNING : This enum is serialized as the ordinal. Only add
   * new enums at the end.
   */
<span class="nc" id="L122">  public enum HeaderMetadataType {</span>
<span class="nc" id="L123">    INSTANT_TIME, TARGET_INSTANT_TIME, SCHEMA, COMMAND_BLOCK_TYPE</span>
  }

  /**
   * Log Metadata footers abstraction for a HoodieLogBlock WARNING : This enum is serialized as the ordinal. Only add
   * new enums at the end.
   */
<span class="nc" id="L130">  public enum FooterMetadataType {</span>
  }

  /**
   * This class is used to store the Location of the Content of a Log Block. It's used when a client chooses for a IO
   * intensive CompactedScanner, the location helps to lazily read contents from the log file
   */
  public static final class HoodieLogBlockContentLocation {

    // The logFile that contains this block
    private final HoodieLogFile logFile;
    // The filePosition in the logFile for the contents of this block
    private final long contentPositionInLogFile;
    // The number of bytes / size of the contents of this block
    private final long blockSize;
    // The final position where the complete block ends
    private final long blockEndPos;

    HoodieLogBlockContentLocation(HoodieLogFile logFile, long contentPositionInLogFile, long blockSize,
<span class="nc" id="L149">        long blockEndPos) {</span>
<span class="nc" id="L150">      this.logFile = logFile;</span>
<span class="nc" id="L151">      this.contentPositionInLogFile = contentPositionInLogFile;</span>
<span class="nc" id="L152">      this.blockSize = blockSize;</span>
<span class="nc" id="L153">      this.blockEndPos = blockEndPos;</span>
<span class="nc" id="L154">    }</span>

    public HoodieLogFile getLogFile() {
<span class="nc" id="L157">      return logFile;</span>
    }

    public long getContentPositionInLogFile() {
<span class="nc" id="L161">      return contentPositionInLogFile;</span>
    }

    public long getBlockSize() {
<span class="nc" id="L165">      return blockSize;</span>
    }

    public long getBlockEndPos() {
<span class="nc" id="L169">      return blockEndPos;</span>
    }
  }

  /**
   * Convert log metadata to bytes 1. Write size of metadata 2. Write enum ordinal 3. Write actual bytes
   */
  public static byte[] getLogMetadataBytes(Map&lt;HeaderMetadataType, String&gt; metadata) throws IOException {
<span class="nc" id="L177">    ByteArrayOutputStream baos = new ByteArrayOutputStream();</span>
<span class="nc" id="L178">    DataOutputStream output = new DataOutputStream(baos);</span>
<span class="nc" id="L179">    output.writeInt(metadata.size());</span>
<span class="nc bnc" id="L180" title="All 2 branches missed.">    for (Map.Entry&lt;HeaderMetadataType, String&gt; entry : metadata.entrySet()) {</span>
<span class="nc" id="L181">      output.writeInt(entry.getKey().ordinal());</span>
<span class="nc" id="L182">      byte[] bytes = entry.getValue().getBytes();</span>
<span class="nc" id="L183">      output.writeInt(bytes.length);</span>
<span class="nc" id="L184">      output.write(bytes);</span>
<span class="nc" id="L185">    }</span>
<span class="nc" id="L186">    return baos.toByteArray();</span>
  }

  /**
   * Convert bytes to LogMetadata, follow the same order as {@link HoodieLogBlock#getLogMetadataBytes}.
   */
  public static Map&lt;HeaderMetadataType, String&gt; getLogMetadata(DataInputStream dis) throws IOException {

<span class="nc" id="L194">    Map&lt;HeaderMetadataType, String&gt; metadata = new HashMap&lt;&gt;();</span>
    // 1. Read the metadata written out
<span class="nc" id="L196">    int metadataCount = dis.readInt();</span>
    try {
<span class="nc bnc" id="L198" title="All 2 branches missed.">      while (metadataCount &gt; 0) {</span>
<span class="nc" id="L199">        int metadataEntryIndex = dis.readInt();</span>
<span class="nc" id="L200">        int metadataEntrySize = dis.readInt();</span>
<span class="nc" id="L201">        byte[] metadataEntry = new byte[metadataEntrySize];</span>
<span class="nc" id="L202">        dis.readFully(metadataEntry, 0, metadataEntrySize);</span>
<span class="nc" id="L203">        metadata.put(HeaderMetadataType.values()[metadataEntryIndex], new String(metadataEntry));</span>
<span class="nc" id="L204">        metadataCount--;</span>
<span class="nc" id="L205">      }</span>
<span class="nc" id="L206">      return metadata;</span>
<span class="nc" id="L207">    } catch (EOFException eof) {</span>
<span class="nc" id="L208">      throw new IOException(&quot;Could not read metadata fields &quot;, eof);</span>
    }
  }

  /**
   * Read or Skip block content of a log block in the log file. Depends on lazy reading enabled in
   * {@link HoodieMergedLogRecordScanner}
   */
  public static byte[] readOrSkipContent(FSDataInputStream inputStream, Integer contentLength, boolean readBlockLazily)
      throws IOException {
<span class="nc" id="L218">    byte[] content = null;</span>
<span class="nc bnc" id="L219" title="All 2 branches missed.">    if (!readBlockLazily) {</span>
      // Read the contents in memory
<span class="nc" id="L221">      content = new byte[contentLength];</span>
<span class="nc" id="L222">      inputStream.readFully(content, 0, contentLength);</span>
    } else {
      // Seek to the end of the content block
<span class="nc" id="L225">      safeSeek(inputStream, inputStream.getPos() + contentLength);</span>
    }
<span class="nc" id="L227">    return content;</span>
  }

  /**
   * When lazyReading of blocks is turned on, inflate the content of a log block from disk.
   */
  protected void inflate() throws HoodieIOException {

    try {
<span class="nc" id="L236">      content = Option.of(new byte[(int) this.getBlockContentLocation().get().getBlockSize()]);</span>
<span class="nc" id="L237">      safeSeek(inputStream, this.getBlockContentLocation().get().getContentPositionInLogFile());</span>
<span class="nc" id="L238">      inputStream.readFully(content.get(), 0, content.get().length);</span>
<span class="nc" id="L239">      safeSeek(inputStream, this.getBlockContentLocation().get().getBlockEndPos());</span>
<span class="nc" id="L240">    } catch (IOException e) {</span>
      // TODO : fs.open() and return inputstream again, need to pass FS configuration
      // because the inputstream might close/timeout for large number of log blocks to be merged
<span class="nc" id="L243">      inflate();</span>
<span class="nc" id="L244">    }</span>
<span class="nc" id="L245">  }</span>

  /**
   * After the content bytes is converted into the required DataStructure by a logBlock, deflate the content to release
   * byte [] and relieve memory pressure when GC kicks in. NOTE: This still leaves the heap fragmented
   */
  protected void deflate() {
<span class="nc" id="L252">    content = Option.empty();</span>
<span class="nc" id="L253">  }</span>

  /**
   * Handles difference in seek behavior for GCS and non-GCS input stream.
   * 
   * @param inputStream Input Stream
   * @param pos Position to seek
   * @throws IOException -
   */
  private static void safeSeek(FSDataInputStream inputStream, long pos) throws IOException {
    try {
<span class="nc" id="L264">      inputStream.seek(pos);</span>
<span class="nc" id="L265">    } catch (EOFException e) {</span>
<span class="nc bnc" id="L266" title="All 2 branches missed.">      if (FSUtils.isGCSInputStream(inputStream)) {</span>
<span class="nc" id="L267">        inputStream.seek(pos - 1);</span>
      } else {
<span class="nc" id="L269">        throw e;</span>
      }
<span class="nc" id="L271">    }</span>
<span class="nc" id="L272">  }</span>
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.5.201910111838</span></div></body></html>