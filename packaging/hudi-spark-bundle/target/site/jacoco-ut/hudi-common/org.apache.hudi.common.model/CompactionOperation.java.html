<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="fr"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../jacoco-resources/report.gif" type="image/gif"/><title>CompactionOperation.java</title><link rel="stylesheet" href="../../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../../index.html" class="el_report">hudi-spark-bundle_2.11</a> &gt; <a href="../index.html" class="el_bundle">hudi-common</a> &gt; <a href="index.source.html" class="el_package">org.apache.hudi.common.model</a> &gt; <span class="el_source">CompactionOperation.java</span></div><h1>CompactionOperation.java</h1><pre class="source lang-java linenums">/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.hudi.common.model;

import org.apache.hudi.avro.model.HoodieCompactionOperation;
import org.apache.hudi.common.util.FSUtils;
import org.apache.hudi.common.util.Option;

import org.apache.hadoop.fs.Path;

import java.io.Serializable;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.stream.Collectors;

/**
 * Encapsulates all the needed information about a compaction and make a decision whether this compaction is effective
 * or not.
 */
<span class="nc bnc" id="L39" title="All 2 branches missed.">public class CompactionOperation implements Serializable {</span>

  private String baseInstantTime;
  private Option&lt;String&gt; dataFileCommitTime;
  private List&lt;String&gt; deltaFileNames;
  private Option&lt;String&gt; dataFileName;
  private HoodieFileGroupId id;
  private Map&lt;String, Double&gt; metrics;

  // Only for serialization/de-serialization
  @Deprecated
<span class="nc" id="L50">  public CompactionOperation() {}</span>

  public CompactionOperation(String fileId, String partitionPath, String baseInstantTime,
      Option&lt;String&gt; dataFileCommitTime, List&lt;String&gt; deltaFileNames, Option&lt;String&gt; dataFileName,
<span class="nc" id="L54">      Map&lt;String, Double&gt; metrics) {</span>
<span class="nc" id="L55">    this.baseInstantTime = baseInstantTime;</span>
<span class="nc" id="L56">    this.dataFileCommitTime = dataFileCommitTime;</span>
<span class="nc" id="L57">    this.deltaFileNames = deltaFileNames;</span>
<span class="nc" id="L58">    this.dataFileName = dataFileName;</span>
<span class="nc" id="L59">    this.id = new HoodieFileGroupId(partitionPath, fileId);</span>
<span class="nc" id="L60">    this.metrics = metrics;</span>
<span class="nc" id="L61">  }</span>

  public CompactionOperation(Option&lt;HoodieBaseFile&gt; dataFile, String partitionPath, List&lt;HoodieLogFile&gt; logFiles,
<span class="nc" id="L64">      Map&lt;String, Double&gt; metrics) {</span>
<span class="nc bnc" id="L65" title="All 2 branches missed.">    if (dataFile.isPresent()) {</span>
<span class="nc" id="L66">      this.baseInstantTime = dataFile.get().getCommitTime();</span>
<span class="nc" id="L67">      this.dataFileName = Option.of(dataFile.get().getFileName());</span>
<span class="nc" id="L68">      this.id = new HoodieFileGroupId(partitionPath, dataFile.get().getFileId());</span>
<span class="nc" id="L69">      this.dataFileCommitTime = Option.of(dataFile.get().getCommitTime());</span>
    } else {
<span class="nc bnc" id="L71" title="All 4 branches missed.">      assert logFiles.size() &gt; 0;</span>
<span class="nc" id="L72">      this.dataFileName = Option.empty();</span>
<span class="nc" id="L73">      this.baseInstantTime = FSUtils.getBaseCommitTimeFromLogPath(logFiles.get(0).getPath());</span>
<span class="nc" id="L74">      this.id = new HoodieFileGroupId(partitionPath, FSUtils.getFileIdFromLogPath(logFiles.get(0).getPath()));</span>
<span class="nc" id="L75">      this.dataFileCommitTime = Option.empty();</span>
    }

<span class="nc" id="L78">    this.deltaFileNames = logFiles.stream().map(s -&gt; s.getPath().getName()).collect(Collectors.toList());</span>
<span class="nc" id="L79">    this.metrics = metrics;</span>
<span class="nc" id="L80">  }</span>

  public String getBaseInstantTime() {
<span class="nc" id="L83">    return baseInstantTime;</span>
  }

  public Option&lt;String&gt; getDataFileCommitTime() {
<span class="nc" id="L87">    return dataFileCommitTime;</span>
  }

  public List&lt;String&gt; getDeltaFileNames() {
<span class="nc" id="L91">    return deltaFileNames;</span>
  }

  public Option&lt;String&gt; getDataFileName() {
<span class="nc" id="L95">    return dataFileName;</span>
  }

  public String getFileId() {
<span class="nc" id="L99">    return id.getFileId();</span>
  }

  public String getPartitionPath() {
<span class="nc" id="L103">    return id.getPartitionPath();</span>
  }

  public Map&lt;String, Double&gt; getMetrics() {
<span class="nc" id="L107">    return metrics;</span>
  }

  public HoodieFileGroupId getFileGroupId() {
<span class="nc" id="L111">    return id;</span>
  }

  public Option&lt;HoodieBaseFile&gt; getBaseFile(String basePath, String partitionPath) {
<span class="nc" id="L115">    Path dirPath = FSUtils.getPartitionPath(basePath, partitionPath);</span>
<span class="nc" id="L116">    return dataFileName.map(df -&gt; new HoodieBaseFile(new Path(dirPath, df).toString()));</span>
  }

  /**
   * Convert Avro generated Compaction operation to POJO for Spark RDD operation.
   * 
   * @param operation Hoodie Compaction Operation
   * @return
   */
  public static CompactionOperation convertFromAvroRecordInstance(HoodieCompactionOperation operation) {
<span class="nc" id="L126">    CompactionOperation op = new CompactionOperation();</span>
<span class="nc" id="L127">    op.baseInstantTime = operation.getBaseInstantTime();</span>
<span class="nc" id="L128">    op.dataFileName = Option.ofNullable(operation.getDataFilePath());</span>
<span class="nc" id="L129">    op.dataFileCommitTime = op.dataFileName.map(p -&gt; FSUtils.getCommitTime(new Path(p).getName()));</span>
<span class="nc" id="L130">    op.deltaFileNames = new ArrayList&lt;&gt;(operation.getDeltaFilePaths());</span>
<span class="nc" id="L131">    op.id = new HoodieFileGroupId(operation.getPartitionPath(), operation.getFileId());</span>
<span class="nc bnc" id="L132" title="All 2 branches missed.">    op.metrics = operation.getMetrics() == null ? new HashMap&lt;&gt;() : new HashMap&lt;&gt;(operation.getMetrics());</span>
<span class="nc" id="L133">    return op;</span>
  }

  @Override
  public String toString() {
<span class="nc" id="L138">    return &quot;CompactionOperation{baseInstantTime='&quot; + baseInstantTime + '\'' + &quot;, dataFileCommitTime=&quot;</span>
        + dataFileCommitTime + &quot;, deltaFileNames=&quot; + deltaFileNames + &quot;, dataFileName=&quot; + dataFileName + &quot;, id='&quot; + id
        + '\'' + &quot;, metrics=&quot; + metrics + '}';
  }

  @Override
  public boolean equals(Object o) {
<span class="nc bnc" id="L145" title="All 2 branches missed.">    if (this == o) {</span>
<span class="nc" id="L146">      return true;</span>
    }
<span class="nc bnc" id="L148" title="All 4 branches missed.">    if (o == null || getClass() != o.getClass()) {</span>
<span class="nc" id="L149">      return false;</span>
    }
<span class="nc" id="L151">    CompactionOperation operation = (CompactionOperation) o;</span>
<span class="nc bnc" id="L152" title="All 2 branches missed.">    return Objects.equals(baseInstantTime, operation.baseInstantTime)</span>
<span class="nc bnc" id="L153" title="All 2 branches missed.">        &amp;&amp; Objects.equals(dataFileCommitTime, operation.dataFileCommitTime)</span>
<span class="nc bnc" id="L154" title="All 2 branches missed.">        &amp;&amp; Objects.equals(deltaFileNames, operation.deltaFileNames)</span>
<span class="nc bnc" id="L155" title="All 4 branches missed.">        &amp;&amp; Objects.equals(dataFileName, operation.dataFileName) &amp;&amp; Objects.equals(id, operation.id);</span>
  }

  @Override
  public int hashCode() {
<span class="nc" id="L160">    return Objects.hash(baseInstantTime, id);</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.5.201910111838</span></div></body></html>