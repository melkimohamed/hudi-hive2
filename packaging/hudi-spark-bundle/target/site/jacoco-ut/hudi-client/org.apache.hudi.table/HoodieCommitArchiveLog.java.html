<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="fr"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../jacoco-resources/report.gif" type="image/gif"/><title>HoodieCommitArchiveLog.java</title><link rel="stylesheet" href="../../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../../index.html" class="el_report">hudi-spark-bundle_2.11</a> &gt; <a href="../index.html" class="el_bundle">hudi-client</a> &gt; <a href="index.source.html" class="el_package">org.apache.hudi.table</a> &gt; <span class="el_source">HoodieCommitArchiveLog.java</span></div><h1>HoodieCommitArchiveLog.java</h1><pre class="source lang-java linenums">/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.hudi.table;

import org.apache.hudi.avro.model.HoodieArchivedMetaEntry;
import org.apache.hudi.avro.model.HoodieCompactionPlan;
import org.apache.hudi.avro.model.HoodieRollbackMetadata;
import org.apache.hudi.avro.model.HoodieSavepointMetadata;
import org.apache.hudi.common.model.ActionType;
import org.apache.hudi.common.model.HoodieArchivedLogFile;
import org.apache.hudi.common.model.HoodieCommitMetadata;
import org.apache.hudi.common.model.HoodieRollingStatMetadata;
import org.apache.hudi.common.table.HoodieTableMetaClient;
import org.apache.hudi.common.table.HoodieTimeline;
import org.apache.hudi.common.table.log.HoodieLogFormat;
import org.apache.hudi.common.table.log.HoodieLogFormat.Writer;
import org.apache.hudi.common.table.log.block.HoodieAvroDataBlock;
import org.apache.hudi.common.table.log.block.HoodieLogBlock;
import org.apache.hudi.common.table.log.block.HoodieLogBlock.HeaderMetadataType;
import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;
import org.apache.hudi.common.table.timeline.HoodieArchivedTimeline;
import org.apache.hudi.common.table.timeline.HoodieInstant;
import org.apache.hudi.common.util.AvroUtils;
import org.apache.hudi.common.util.CleanerUtils;
import org.apache.hudi.common.util.CompactionUtils;
import org.apache.hudi.common.util.Option;
import org.apache.hudi.common.util.collection.Pair;
import org.apache.hudi.config.HoodieWriteConfig;
import org.apache.hudi.exception.HoodieCommitException;
import org.apache.hudi.exception.HoodieException;
import org.apache.hudi.exception.HoodieIOException;

import com.fasterxml.jackson.databind.DeserializationFeature;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.apache.avro.Schema;
import org.apache.avro.generic.IndexedRecord;
import org.apache.hadoop.fs.Path;
import org.apache.log4j.LogManager;
import org.apache.log4j.Logger;
import org.apache.spark.api.java.JavaSparkContext;

import java.io.IOException;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.Comparator;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.stream.Collectors;
import java.util.stream.Stream;

/**
 * Archiver to bound the growth of &lt;action&gt;.commit files.
 */
public class HoodieCommitArchiveLog {

<span class="nc" id="L74">  private static final Logger LOG = LogManager.getLogger(HoodieCommitArchiveLog.class);</span>

  private final Path archiveFilePath;
  private final HoodieTableMetaClient metaClient;
  private final HoodieWriteConfig config;
  private Writer writer;

<span class="nc" id="L81">  public HoodieCommitArchiveLog(HoodieWriteConfig config, HoodieTableMetaClient metaClient) {</span>
<span class="nc" id="L82">    this.config = config;</span>
<span class="nc" id="L83">    this.metaClient = metaClient;</span>
<span class="nc" id="L84">    this.archiveFilePath = HoodieArchivedTimeline.getArchiveLogPath(metaClient.getArchivePath());</span>
<span class="nc" id="L85">  }</span>

  private Writer openWriter() {
    try {
<span class="nc bnc" id="L89" title="All 2 branches missed.">      if (this.writer == null) {</span>
<span class="nc" id="L90">        return HoodieLogFormat.newWriterBuilder().onParentPath(archiveFilePath.getParent())</span>
<span class="nc" id="L91">            .withFileId(archiveFilePath.getName()).withFileExtension(HoodieArchivedLogFile.ARCHIVE_EXTENSION)</span>
<span class="nc" id="L92">            .withFs(metaClient.getFs()).overBaseCommit(&quot;&quot;).build();</span>
      } else {
<span class="nc" id="L94">        return this.writer;</span>
      }
<span class="nc" id="L96">    } catch (InterruptedException | IOException e) {</span>
<span class="nc" id="L97">      throw new HoodieException(&quot;Unable to initialize HoodieLogFormat writer&quot;, e);</span>
    }
  }

  private void close() {
    try {
<span class="nc bnc" id="L103" title="All 2 branches missed.">      if (this.writer != null) {</span>
<span class="nc" id="L104">        this.writer.close();</span>
      }
<span class="nc" id="L106">    } catch (IOException e) {</span>
<span class="nc" id="L107">      throw new HoodieException(&quot;Unable to close HoodieLogFormat writer&quot;, e);</span>
<span class="nc" id="L108">    }</span>
<span class="nc" id="L109">  }</span>

  /**
   * Check if commits need to be archived. If yes, archive commits.
   */
  public boolean archiveIfRequired(final JavaSparkContext jsc) throws IOException {
    try {
<span class="nc" id="L116">      List&lt;HoodieInstant&gt; instantsToArchive = getInstantsToArchive(jsc).collect(Collectors.toList());</span>

<span class="nc" id="L118">      boolean success = true;</span>
<span class="nc bnc" id="L119" title="All 2 branches missed.">      if (!instantsToArchive.isEmpty()) {</span>
<span class="nc" id="L120">        this.writer = openWriter();</span>
<span class="nc" id="L121">        LOG.info(&quot;Archiving instants &quot; + instantsToArchive);</span>
<span class="nc" id="L122">        archive(instantsToArchive);</span>
<span class="nc" id="L123">        LOG.info(&quot;Deleting archived instants &quot; + instantsToArchive);</span>
<span class="nc" id="L124">        success = deleteArchivedInstants(instantsToArchive);</span>
      } else {
<span class="nc" id="L126">        LOG.info(&quot;No Instants to archive&quot;);</span>
      }

<span class="nc" id="L129">      return success;</span>
    } finally {
<span class="nc" id="L131">      close();</span>
    }
  }

  private Stream&lt;HoodieInstant&gt; getInstantsToArchive(JavaSparkContext jsc) {

    // TODO : rename to max/minInstantsToKeep
<span class="nc" id="L138">    int maxCommitsToKeep = config.getMaxCommitsToKeep();</span>
<span class="nc" id="L139">    int minCommitsToKeep = config.getMinCommitsToKeep();</span>

<span class="nc" id="L141">    HoodieTable table = HoodieTable.getHoodieTable(metaClient, config, jsc);</span>

    // GroupBy each action and limit each action timeline to maxCommitsToKeep
    // TODO: Handle ROLLBACK_ACTION in future
    // ROLLBACK_ACTION is currently not defined in HoodieActiveTimeline
<span class="nc" id="L146">    HoodieTimeline cleanAndRollbackTimeline = table.getActiveTimeline()</span>
<span class="nc" id="L147">        .getTimelineOfActions(Collections.singleton(HoodieTimeline.CLEAN_ACTION)).filterCompletedInstants();</span>
<span class="nc" id="L148">    Stream&lt;HoodieInstant&gt; instants = cleanAndRollbackTimeline.getInstants()</span>
<span class="nc" id="L149">        .collect(Collectors.groupingBy(HoodieInstant::getAction)).values().stream().map(hoodieInstants -&gt; {</span>
<span class="nc bnc" id="L150" title="All 2 branches missed.">          if (hoodieInstants.size() &gt; maxCommitsToKeep) {</span>
<span class="nc" id="L151">            return hoodieInstants.subList(0, hoodieInstants.size() - minCommitsToKeep);</span>
          } else {
<span class="nc" id="L153">            return new ArrayList&lt;HoodieInstant&gt;();</span>
          }
<span class="nc" id="L155">        }).flatMap(Collection::stream);</span>

    // TODO (na) : Add a way to return actions associated with a timeline and then merge/unify
    // with logic above to avoid Stream.concats
<span class="nc" id="L159">    HoodieTimeline commitTimeline = table.getCompletedCommitsTimeline();</span>
<span class="nc" id="L160">    Option&lt;HoodieInstant&gt; oldestPendingCompactionInstant =</span>
<span class="nc" id="L161">        table.getActiveTimeline().filterPendingCompactionTimeline().firstInstant();</span>

    // We cannot have any holes in the commit timeline. We cannot archive any commits which are
    // made after the first savepoint present.
<span class="nc" id="L165">    Option&lt;HoodieInstant&gt; firstSavepoint = table.getCompletedSavepointTimeline().firstInstant();</span>
<span class="nc bnc" id="L166" title="All 4 branches missed.">    if (!commitTimeline.empty() &amp;&amp; commitTimeline.countInstants() &gt; maxCommitsToKeep) {</span>
      // Actually do the commits
<span class="nc" id="L168">      instants = Stream.concat(instants, commitTimeline.getInstants().filter(s -&gt; {</span>
        // if no savepoint present, then dont filter
<span class="nc bnc" id="L170" title="All 4 branches missed.">        return !(firstSavepoint.isPresent() &amp;&amp; HoodieTimeline.compareTimestamps(firstSavepoint.get().getTimestamp(),</span>
<span class="nc" id="L171">            s.getTimestamp(), HoodieTimeline.LESSER_OR_EQUAL));</span>
<span class="nc" id="L172">      }).filter(s -&gt; {</span>
        // Ensure commits &gt;= oldest pending compaction commit is retained
<span class="nc" id="L174">        return oldestPendingCompactionInstant.map(instant -&gt; HoodieTimeline.compareTimestamps(instant.getTimestamp(), s.getTimestamp(), HoodieTimeline.GREATER)).orElse(true);</span>
<span class="nc" id="L175">      }).limit(commitTimeline.countInstants() - minCommitsToKeep));</span>
    }

    // For archiving and cleaning instants, we need to include intermediate state files if they exist
<span class="nc" id="L179">    HoodieActiveTimeline rawActiveTimeline = new HoodieActiveTimeline(metaClient, false);</span>
<span class="nc" id="L180">    Map&lt;Pair&lt;String, String&gt;, List&lt;HoodieInstant&gt;&gt; groupByTsAction = rawActiveTimeline.getInstants()</span>
<span class="nc" id="L181">        .collect(Collectors.groupingBy(i -&gt; Pair.of(i.getTimestamp(),</span>
<span class="nc" id="L182">            HoodieInstant.getComparableAction(i.getAction()))));</span>

<span class="nc" id="L184">    return instants.flatMap(hoodieInstant -&gt;</span>
<span class="nc" id="L185">        groupByTsAction.get(Pair.of(hoodieInstant.getTimestamp(),</span>
<span class="nc" id="L186">            HoodieInstant.getComparableAction(hoodieInstant.getAction()))).stream());</span>
  }

  private boolean deleteArchivedInstants(List&lt;HoodieInstant&gt; archivedInstants) throws IOException {
<span class="nc" id="L190">    LOG.info(&quot;Deleting instants &quot; + archivedInstants);</span>
<span class="nc" id="L191">    boolean success = true;</span>
<span class="nc bnc" id="L192" title="All 2 branches missed.">    for (HoodieInstant archivedInstant : archivedInstants) {</span>
<span class="nc" id="L193">      Path commitFile = new Path(metaClient.getMetaPath(), archivedInstant.getFileName());</span>
      try {
<span class="nc bnc" id="L195" title="All 2 branches missed.">        if (metaClient.getFs().exists(commitFile)) {</span>
<span class="nc" id="L196">          success &amp;= metaClient.getFs().delete(commitFile, false);</span>
<span class="nc" id="L197">          LOG.info(&quot;Archived and deleted instant file &quot; + commitFile);</span>
        }
<span class="nc" id="L199">      } catch (IOException e) {</span>
<span class="nc" id="L200">        throw new HoodieIOException(&quot;Failed to delete archived instant &quot; + archivedInstant, e);</span>
<span class="nc" id="L201">      }</span>
<span class="nc" id="L202">    }</span>

    // Remove older meta-data from auxiliary path too
<span class="nc bnc" id="L205" title="All 4 branches missed.">    Option&lt;HoodieInstant&gt; latestCommitted = Option.fromJavaOptional(archivedInstants.stream().filter(i -&gt; i.isCompleted() &amp;&amp; (i.getAction().equals(HoodieTimeline.COMMIT_ACTION)</span>
<span class="nc bnc" id="L206" title="All 2 branches missed.">        || (i.getAction().equals(HoodieTimeline.DELTA_COMMIT_ACTION)))).max(Comparator.comparing(HoodieInstant::getTimestamp)));</span>
<span class="nc" id="L207">    LOG.info(&quot;Latest Committed Instant=&quot; + latestCommitted);</span>
<span class="nc bnc" id="L208" title="All 2 branches missed.">    if (latestCommitted.isPresent()) {</span>
<span class="nc" id="L209">      success &amp;= deleteAllInstantsOlderorEqualsInAuxMetaFolder(latestCommitted.get());</span>
    }
<span class="nc" id="L211">    return success;</span>
  }

  /**
   * Remove older instants from auxiliary meta folder.
   *
   * @param thresholdInstant Hoodie Instant
   * @return success if all eligible file deleted successfully
   * @throws IOException in case of error
   */
  private boolean deleteAllInstantsOlderorEqualsInAuxMetaFolder(HoodieInstant thresholdInstant) throws IOException {
<span class="nc" id="L222">    List&lt;HoodieInstant&gt; instants = metaClient.scanHoodieInstantsFromFileSystem(</span>
<span class="nc" id="L223">        new Path(metaClient.getMetaAuxiliaryPath()), HoodieActiveTimeline.VALID_EXTENSIONS_IN_ACTIVE_TIMELINE, false);</span>

<span class="nc" id="L225">    List&lt;HoodieInstant&gt; instantsToBeDeleted =</span>
<span class="nc" id="L226">        instants.stream().filter(instant1 -&gt; HoodieTimeline.compareTimestamps(instant1.getTimestamp(),</span>
<span class="nc" id="L227">            thresholdInstant.getTimestamp(), HoodieTimeline.LESSER_OR_EQUAL)).collect(Collectors.toList());</span>

<span class="nc" id="L229">    boolean success = true;</span>
<span class="nc bnc" id="L230" title="All 2 branches missed.">    for (HoodieInstant deleteInstant : instantsToBeDeleted) {</span>
<span class="nc" id="L231">      LOG.info(&quot;Deleting instant &quot; + deleteInstant + &quot; in auxiliary meta path &quot; + metaClient.getMetaAuxiliaryPath());</span>
<span class="nc" id="L232">      Path metaFile = new Path(metaClient.getMetaAuxiliaryPath(), deleteInstant.getFileName());</span>
<span class="nc bnc" id="L233" title="All 2 branches missed.">      if (metaClient.getFs().exists(metaFile)) {</span>
<span class="nc" id="L234">        success &amp;= metaClient.getFs().delete(metaFile, false);</span>
<span class="nc" id="L235">        LOG.info(&quot;Deleted instant file in auxiliary metapath : &quot; + metaFile);</span>
      }
<span class="nc" id="L237">    }</span>
<span class="nc" id="L238">    return success;</span>
  }

  public void archive(List&lt;HoodieInstant&gt; instants) throws HoodieCommitException {
    try {
<span class="nc" id="L243">      HoodieTimeline commitTimeline = metaClient.getActiveTimeline().getAllCommitsTimeline().filterCompletedInstants();</span>
<span class="nc" id="L244">      Schema wrapperSchema = HoodieArchivedMetaEntry.getClassSchema();</span>
<span class="nc" id="L245">      LOG.info(&quot;Wrapper schema &quot; + wrapperSchema.toString());</span>
<span class="nc" id="L246">      List&lt;IndexedRecord&gt; records = new ArrayList&lt;&gt;();</span>
<span class="nc bnc" id="L247" title="All 2 branches missed.">      for (HoodieInstant hoodieInstant : instants) {</span>
        try {
<span class="nc" id="L249">          records.add(convertToAvroRecord(commitTimeline, hoodieInstant));</span>
<span class="nc bnc" id="L250" title="All 2 branches missed.">          if (records.size() &gt;= this.config.getCommitArchivalBatchSize()) {</span>
<span class="nc" id="L251">            writeToFile(wrapperSchema, records);</span>
          }
<span class="nc" id="L253">        } catch (Exception e) {</span>
<span class="nc" id="L254">          LOG.error(&quot;Failed to archive commits, .commit file: &quot; + hoodieInstant.getFileName(), e);</span>
<span class="nc bnc" id="L255" title="All 2 branches missed.">          if (this.config.isFailOnTimelineArchivingEnabled()) {</span>
<span class="nc" id="L256">            throw e;</span>
          }
<span class="nc" id="L258">        }</span>
<span class="nc" id="L259">      }</span>
<span class="nc" id="L260">      writeToFile(wrapperSchema, records);</span>
<span class="nc" id="L261">    } catch (Exception e) {</span>
<span class="nc" id="L262">      throw new HoodieCommitException(&quot;Failed to archive commits&quot;, e);</span>
<span class="nc" id="L263">    }</span>
<span class="nc" id="L264">  }</span>

  public Path getArchiveFilePath() {
<span class="nc" id="L267">    return archiveFilePath;</span>
  }

  private void writeToFile(Schema wrapperSchema, List&lt;IndexedRecord&gt; records) throws Exception {
<span class="nc bnc" id="L271" title="All 2 branches missed.">    if (records.size() &gt; 0) {</span>
<span class="nc" id="L272">      Map&lt;HeaderMetadataType, String&gt; header = new HashMap&lt;&gt;();</span>
<span class="nc" id="L273">      header.put(HoodieLogBlock.HeaderMetadataType.SCHEMA, wrapperSchema.toString());</span>
<span class="nc" id="L274">      HoodieAvroDataBlock block = new HoodieAvroDataBlock(records, header);</span>
<span class="nc" id="L275">      this.writer = writer.appendBlock(block);</span>
<span class="nc" id="L276">      records.clear();</span>
    }
<span class="nc" id="L278">  }</span>

  private IndexedRecord convertToAvroRecord(HoodieTimeline commitTimeline, HoodieInstant hoodieInstant)
      throws IOException {
<span class="nc" id="L282">    HoodieArchivedMetaEntry archivedMetaWrapper = new HoodieArchivedMetaEntry();</span>
<span class="nc" id="L283">    archivedMetaWrapper.setCommitTime(hoodieInstant.getTimestamp());</span>
<span class="nc" id="L284">    archivedMetaWrapper.setActionState(hoodieInstant.getState().name());</span>
<span class="nc bnc" id="L285" title="All 7 branches missed.">    switch (hoodieInstant.getAction()) {</span>
      case HoodieTimeline.CLEAN_ACTION: {
<span class="nc bnc" id="L287" title="All 2 branches missed.">        if (hoodieInstant.isCompleted()) {</span>
<span class="nc" id="L288">          archivedMetaWrapper.setHoodieCleanMetadata(CleanerUtils.getCleanerMetadata(metaClient, hoodieInstant));</span>
        } else {
<span class="nc" id="L290">          archivedMetaWrapper.setHoodieCleanerPlan(CleanerUtils.getCleanerPlan(metaClient, hoodieInstant));</span>
        }
<span class="nc" id="L292">        archivedMetaWrapper.setActionType(ActionType.clean.name());</span>
<span class="nc" id="L293">        break;</span>
      }
      case HoodieTimeline.COMMIT_ACTION: {
<span class="nc" id="L296">        HoodieCommitMetadata commitMetadata = HoodieCommitMetadata</span>
<span class="nc" id="L297">            .fromBytes(commitTimeline.getInstantDetails(hoodieInstant).get(), HoodieCommitMetadata.class);</span>
<span class="nc" id="L298">        archivedMetaWrapper.setHoodieCommitMetadata(commitMetadataConverter(commitMetadata));</span>
<span class="nc" id="L299">        archivedMetaWrapper.setActionType(ActionType.commit.name());</span>
<span class="nc" id="L300">        break;</span>
      }
      case HoodieTimeline.ROLLBACK_ACTION: {
<span class="nc" id="L303">        archivedMetaWrapper.setHoodieRollbackMetadata(AvroUtils.deserializeAvroMetadata(</span>
<span class="nc" id="L304">            commitTimeline.getInstantDetails(hoodieInstant).get(), HoodieRollbackMetadata.class));</span>
<span class="nc" id="L305">        archivedMetaWrapper.setActionType(ActionType.rollback.name());</span>
<span class="nc" id="L306">        break;</span>
      }
      case HoodieTimeline.SAVEPOINT_ACTION: {
<span class="nc" id="L309">        archivedMetaWrapper.setHoodieSavePointMetadata(AvroUtils.deserializeAvroMetadata(</span>
<span class="nc" id="L310">            commitTimeline.getInstantDetails(hoodieInstant).get(), HoodieSavepointMetadata.class));</span>
<span class="nc" id="L311">        archivedMetaWrapper.setActionType(ActionType.savepoint.name());</span>
<span class="nc" id="L312">        break;</span>
      }
      case HoodieTimeline.DELTA_COMMIT_ACTION: {
<span class="nc" id="L315">        HoodieCommitMetadata commitMetadata = HoodieCommitMetadata</span>
<span class="nc" id="L316">            .fromBytes(commitTimeline.getInstantDetails(hoodieInstant).get(), HoodieCommitMetadata.class);</span>
<span class="nc" id="L317">        archivedMetaWrapper.setHoodieCommitMetadata(commitMetadataConverter(commitMetadata));</span>
<span class="nc" id="L318">        archivedMetaWrapper.setActionType(ActionType.commit.name());</span>
<span class="nc" id="L319">        break;</span>
      }
      case HoodieTimeline.COMPACTION_ACTION: {
<span class="nc" id="L322">        HoodieCompactionPlan plan = CompactionUtils.getCompactionPlan(metaClient, hoodieInstant.getTimestamp());</span>
<span class="nc" id="L323">        archivedMetaWrapper.setHoodieCompactionPlan(plan);</span>
<span class="nc" id="L324">        archivedMetaWrapper.setActionType(ActionType.compaction.name());</span>
<span class="nc" id="L325">        break;</span>
      }
      default: {
<span class="nc" id="L328">        throw new UnsupportedOperationException(&quot;Action not fully supported yet&quot;);</span>
      }
    }
<span class="nc" id="L331">    return archivedMetaWrapper;</span>
  }

  public org.apache.hudi.avro.model.HoodieCommitMetadata commitMetadataConverter(
      HoodieCommitMetadata hoodieCommitMetadata) {
<span class="nc" id="L336">    ObjectMapper mapper = new ObjectMapper();</span>
    // Need this to ignore other public get() methods
<span class="nc" id="L338">    mapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);</span>
<span class="nc" id="L339">    org.apache.hudi.avro.model.HoodieCommitMetadata avroMetaData =</span>
<span class="nc" id="L340">        mapper.convertValue(hoodieCommitMetadata, org.apache.hudi.avro.model.HoodieCommitMetadata.class);</span>
    // Do not archive Rolling Stats, cannot set to null since AVRO will throw null pointer
<span class="nc" id="L342">    avroMetaData.getExtraMetadata().put(HoodieRollingStatMetadata.ROLLING_STAT_METADATA_KEY, &quot;&quot;);</span>
<span class="nc" id="L343">    return avroMetaData;</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.5.201910111838</span></div></body></html>