<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="fr"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../jacoco-resources/report.gif" type="image/gif"/><title>HoodieKeyLookupHandle.java</title><link rel="stylesheet" href="../../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../../index.html" class="el_report">hudi-spark-bundle_2.11</a> &gt; <a href="../index.html" class="el_bundle">hudi-client</a> &gt; <a href="index.source.html" class="el_package">org.apache.hudi.io</a> &gt; <span class="el_source">HoodieKeyLookupHandle.java</span></div><h1>HoodieKeyLookupHandle.java</h1><pre class="source lang-java linenums">/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.hudi.io;

import org.apache.hudi.common.bloom.filter.BloomFilter;
import org.apache.hudi.common.model.HoodieBaseFile;
import org.apache.hudi.common.model.HoodieRecordPayload;
import org.apache.hudi.common.model.HoodieTableType;
import org.apache.hudi.common.util.HoodieTimer;
import org.apache.hudi.common.util.ParquetUtils;
import org.apache.hudi.common.util.collection.Pair;
import org.apache.hudi.config.HoodieWriteConfig;
import org.apache.hudi.exception.HoodieIndexException;
import org.apache.hudi.table.HoodieTable;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.log4j.LogManager;
import org.apache.log4j.Logger;

import java.util.ArrayList;
import java.util.HashSet;
import java.util.List;
import java.util.Set;

/**
 * Takes a bunch of keys and returns ones that are present in the file group.
 */
public class HoodieKeyLookupHandle&lt;T extends HoodieRecordPayload&gt; extends HoodieReadHandle&lt;T&gt; {

<span class="nc" id="L47">  private static final Logger LOG = LogManager.getLogger(HoodieKeyLookupHandle.class);</span>

  private final HoodieTableType tableType;

  private final BloomFilter bloomFilter;

  private final List&lt;String&gt; candidateRecordKeys;

  private long totalKeysChecked;

  public HoodieKeyLookupHandle(HoodieWriteConfig config, HoodieTable&lt;T&gt; hoodieTable,
                               Pair&lt;String, String&gt; partitionPathFilePair) {
<span class="nc" id="L59">    super(config, null, hoodieTable, partitionPathFilePair);</span>
<span class="nc" id="L60">    this.tableType = hoodieTable.getMetaClient().getTableType();</span>
<span class="nc" id="L61">    this.candidateRecordKeys = new ArrayList&lt;&gt;();</span>
<span class="nc" id="L62">    this.totalKeysChecked = 0;</span>
<span class="nc" id="L63">    HoodieTimer timer = new HoodieTimer().startTimer();</span>
<span class="nc" id="L64">    this.bloomFilter = ParquetUtils.readBloomFilterFromParquetMetadata(hoodieTable.getHadoopConf(),</span>
<span class="nc" id="L65">        new Path(getLatestDataFile().getPath()));</span>
<span class="nc" id="L66">    LOG.info(String.format(&quot;Read bloom filter from %s in %d ms&quot;, partitionPathFilePair, timer.endTimer()));</span>
<span class="nc" id="L67">  }</span>

  /**
   * Given a list of row keys and one file, return only row keys existing in that file.
   */
  public static List&lt;String&gt; checkCandidatesAgainstFile(Configuration configuration, List&lt;String&gt; candidateRecordKeys,
                                                        Path filePath) throws HoodieIndexException {
<span class="nc" id="L74">    List&lt;String&gt; foundRecordKeys = new ArrayList&lt;&gt;();</span>
    try {
      // Load all rowKeys from the file, to double-confirm
<span class="nc bnc" id="L77" title="All 2 branches missed.">      if (!candidateRecordKeys.isEmpty()) {</span>
<span class="nc" id="L78">        HoodieTimer timer = new HoodieTimer().startTimer();</span>
<span class="nc" id="L79">        Set&lt;String&gt; fileRowKeys =</span>
<span class="nc" id="L80">            ParquetUtils.filterParquetRowKeys(configuration, filePath, new HashSet&lt;&gt;(candidateRecordKeys));</span>
<span class="nc" id="L81">        foundRecordKeys.addAll(fileRowKeys);</span>
<span class="nc" id="L82">        LOG.info(String.format(&quot;Checked keys against file %s, in %d ms. #candidates (%d) #found (%d)&quot;, filePath,</span>
<span class="nc" id="L83">            timer.endTimer(), candidateRecordKeys.size(), foundRecordKeys.size()));</span>
<span class="nc bnc" id="L84" title="All 2 branches missed.">        if (LOG.isDebugEnabled()) {</span>
<span class="nc" id="L85">          LOG.debug(&quot;Keys matching for file &quot; + filePath + &quot; =&gt; &quot; + foundRecordKeys);</span>
        }
      }
<span class="nc" id="L88">    } catch (Exception e) {</span>
<span class="nc" id="L89">      throw new HoodieIndexException(&quot;Error checking candidate keys against file.&quot;, e);</span>
<span class="nc" id="L90">    }</span>
<span class="nc" id="L91">    return foundRecordKeys;</span>
  }

  /**
   * Adds the key for look up.
   */
  public void addKey(String recordKey) {
    // check record key against bloom filter of current file &amp; add to possible keys if needed
<span class="nc bnc" id="L99" title="All 2 branches missed.">    if (bloomFilter.mightContain(recordKey)) {</span>
<span class="nc bnc" id="L100" title="All 2 branches missed.">      if (LOG.isDebugEnabled()) {</span>
<span class="nc" id="L101">        LOG.debug(&quot;Record key &quot; + recordKey + &quot; matches bloom filter in  &quot; + partitionPathFilePair);</span>
      }
<span class="nc" id="L103">      candidateRecordKeys.add(recordKey);</span>
    }
<span class="nc" id="L105">    totalKeysChecked++;</span>
<span class="nc" id="L106">  }</span>

  /**
   * Of all the keys, that were added, return a list of keys that were actually found in the file group.
   */
  public KeyLookupResult getLookupResult() {
<span class="nc bnc" id="L112" title="All 2 branches missed.">    if (LOG.isDebugEnabled()) {</span>
<span class="nc" id="L113">      LOG.debug(&quot;#The candidate row keys for &quot; + partitionPathFilePair + &quot; =&gt; &quot; + candidateRecordKeys);</span>
    }

<span class="nc" id="L116">    HoodieBaseFile dataFile = getLatestDataFile();</span>
<span class="nc" id="L117">    List&lt;String&gt; matchingKeys =</span>
<span class="nc" id="L118">        checkCandidatesAgainstFile(hoodieTable.getHadoopConf(), candidateRecordKeys, new Path(dataFile.getPath()));</span>
<span class="nc" id="L119">    LOG.info(</span>
<span class="nc" id="L120">        String.format(&quot;Total records (%d), bloom filter candidates (%d)/fp(%d), actual matches (%d)&quot;, totalKeysChecked,</span>
<span class="nc" id="L121">            candidateRecordKeys.size(), candidateRecordKeys.size() - matchingKeys.size(), matchingKeys.size()));</span>
<span class="nc" id="L122">    return new KeyLookupResult(partitionPathFilePair.getRight(), partitionPathFilePair.getLeft(),</span>
<span class="nc" id="L123">        dataFile.getCommitTime(), matchingKeys);</span>
  }

  /**
   * Encapsulates the result from a key lookup.
   */
  public static class KeyLookupResult {

    private final String fileId;
    private final String baseInstantTime;
    private final List&lt;String&gt; matchingRecordKeys;
    private final String partitionPath;

    public KeyLookupResult(String fileId, String partitionPath, String baseInstantTime,
<span class="nc" id="L137">                           List&lt;String&gt; matchingRecordKeys) {</span>
<span class="nc" id="L138">      this.fileId = fileId;</span>
<span class="nc" id="L139">      this.partitionPath = partitionPath;</span>
<span class="nc" id="L140">      this.baseInstantTime = baseInstantTime;</span>
<span class="nc" id="L141">      this.matchingRecordKeys = matchingRecordKeys;</span>
<span class="nc" id="L142">    }</span>

    public String getFileId() {
<span class="nc" id="L145">      return fileId;</span>
    }

    public String getBaseInstantTime() {
<span class="nc" id="L149">      return baseInstantTime;</span>
    }

    public String getPartitionPath() {
<span class="nc" id="L153">      return partitionPath;</span>
    }

    public List&lt;String&gt; getMatchingRecordKeys() {
<span class="nc" id="L157">      return matchingRecordKeys;</span>
    }
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.5.201910111838</span></div></body></html>