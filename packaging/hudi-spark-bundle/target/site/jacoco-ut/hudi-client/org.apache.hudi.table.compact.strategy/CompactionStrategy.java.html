<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="fr"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../jacoco-resources/report.gif" type="image/gif"/><title>CompactionStrategy.java</title><link rel="stylesheet" href="../../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../../index.html" class="el_report">hudi-spark-bundle_2.11</a> &gt; <a href="../index.html" class="el_bundle">hudi-client</a> &gt; <a href="index.source.html" class="el_package">org.apache.hudi.table.compact.strategy</a> &gt; <span class="el_source">CompactionStrategy.java</span></div><h1>CompactionStrategy.java</h1><pre class="source lang-java linenums">/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.hudi.table.compact.strategy;

import org.apache.hudi.avro.model.HoodieCompactionOperation;
import org.apache.hudi.avro.model.HoodieCompactionPlan;
import org.apache.hudi.common.model.HoodieBaseFile;
import org.apache.hudi.common.model.HoodieLogFile;
import org.apache.hudi.common.util.CompactionUtils;
import org.apache.hudi.common.util.FSUtils;
import org.apache.hudi.common.util.Option;
import org.apache.hudi.config.HoodieWriteConfig;
import org.apache.hudi.table.compact.HoodieMergeOnReadTableCompactor;

import java.io.Serializable;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

/**
 * Strategy for compaction. Pluggable implementation to define how compaction should be done. The over-ridden
 * implementations of this abstract class can capture the relevant metrics to order and filter the final list of
 * compaction operation to run in a single compaction. Implementation of CompactionStrategy cannot hold any state.
 * Difference instantiations can be passed in every time
 *
 * @see HoodieMergeOnReadTableCompactor
 */
<span class="nc" id="L44">public abstract class CompactionStrategy implements Serializable {</span>

  public static final String TOTAL_IO_READ_MB = &quot;TOTAL_IO_READ_MB&quot;;
  public static final String TOTAL_IO_WRITE_MB = &quot;TOTAL_IO_WRITE_MB&quot;;
  public static final String TOTAL_IO_MB = &quot;TOTAL_IO_MB&quot;;
  public static final String TOTAL_LOG_FILE_SIZE = &quot;TOTAL_LOG_FILES_SIZE&quot;;
  public static final String TOTAL_LOG_FILES = &quot;TOTAL_LOG_FILES&quot;;

  /**
   * Callback hook when a HoodieCompactionOperation is created. Individual strategies can capture the metrics they need
   * to decide on the priority.
   *
   * @param dataFile - Base file to compact
   * @param partitionPath - Partition path
   * @param logFiles - List of log files to compact with the base file
   * @return Map[String, Object] - metrics captured
   */
  public Map&lt;String, Double&gt; captureMetrics(HoodieWriteConfig writeConfig, Option&lt;HoodieBaseFile&gt; dataFile,
      String partitionPath, List&lt;HoodieLogFile&gt; logFiles) {
<span class="nc" id="L63">    Map&lt;String, Double&gt; metrics = new HashMap&lt;&gt;();</span>
<span class="nc" id="L64">    long defaultMaxParquetFileSize = writeConfig.getParquetMaxFileSize();</span>
    // Total size of all the log files
<span class="nc bnc" id="L66" title="All 2 branches missed.">    Long totalLogFileSize = logFiles.stream().map(HoodieLogFile::getFileSize).filter(size -&gt; size &gt;= 0)</span>
<span class="nc" id="L67">        .reduce(Long::sum).orElse(0L);</span>
    // Total read will be the base file + all the log files
<span class="nc" id="L69">    Long totalIORead =</span>
<span class="nc bnc" id="L70" title="All 2 branches missed.">        FSUtils.getSizeInMB((dataFile.isPresent() ? dataFile.get().getFileSize() : 0L) + totalLogFileSize);</span>
    // Total write will be similar to the size of the base file
<span class="nc" id="L72">    Long totalIOWrite =</span>
<span class="nc bnc" id="L73" title="All 2 branches missed.">        FSUtils.getSizeInMB(dataFile.isPresent() ? dataFile.get().getFileSize() : defaultMaxParquetFileSize);</span>
    // Total IO will the the IO for read + write
<span class="nc" id="L75">    long totalIO = totalIORead + totalIOWrite;</span>
    // Save these metrics and we will use during the filter
<span class="nc" id="L77">    metrics.put(TOTAL_IO_READ_MB, totalIORead.doubleValue());</span>
<span class="nc" id="L78">    metrics.put(TOTAL_IO_WRITE_MB, totalIOWrite.doubleValue());</span>
<span class="nc" id="L79">    metrics.put(TOTAL_IO_MB, (double) totalIO);</span>
<span class="nc" id="L80">    metrics.put(TOTAL_LOG_FILE_SIZE, totalLogFileSize.doubleValue());</span>
<span class="nc" id="L81">    metrics.put(TOTAL_LOG_FILES, (double) logFiles.size());</span>
<span class="nc" id="L82">    return metrics;</span>
  }

  /**
   * Generate Compaction plan. Allows clients to order and filter the list of compactions to be set. The default
   * implementation takes care of setting compactor Id from configuration allowing subclasses to only worry about
   * ordering and filtering compaction operations
   *
   * @param writeConfig Hoodie Write Config
   * @param operations Compaction Operations to be ordered and filtered
   * @param pendingCompactionPlans Pending Compaction Plans for strategy to schedule next compaction plan
   * @return Compaction plan to be scheduled.
   */
  public HoodieCompactionPlan generateCompactionPlan(HoodieWriteConfig writeConfig,
      List&lt;HoodieCompactionOperation&gt; operations, List&lt;HoodieCompactionPlan&gt; pendingCompactionPlans) {
    // Strategy implementation can overload this method to set specific compactor-id
<span class="nc" id="L98">    return HoodieCompactionPlan.newBuilder()</span>
<span class="nc" id="L99">        .setOperations(orderAndFilter(writeConfig, operations, pendingCompactionPlans))</span>
<span class="nc" id="L100">        .setVersion(CompactionUtils.LATEST_COMPACTION_METADATA_VERSION).build();</span>
  }

  /**
   * Order and Filter the list of compactions. Use the metrics captured with the captureMetrics to order and filter out
   * compactions
   *
   * @param writeConfig config for this compaction is passed in
   * @param operations list of compactions collected
   * @param pendingCompactionPlans Pending Compaction Plans for strategy to schedule next compaction plan
   * @return list of compactions to perform in this run
   */
  public List&lt;HoodieCompactionOperation&gt; orderAndFilter(HoodieWriteConfig writeConfig,
      List&lt;HoodieCompactionOperation&gt; operations, List&lt;HoodieCompactionPlan&gt; pendingCompactionPlans) {
<span class="nc" id="L114">    return operations;</span>
  }

  /**
   * Filter the partition paths based on compaction strategy.
   * 
   * @param writeConfig
   * @param allPartitionPaths
   * @return
   */
  public List&lt;String&gt; filterPartitionPaths(HoodieWriteConfig writeConfig, List&lt;String&gt; allPartitionPaths) {
<span class="nc" id="L125">    return allPartitionPaths;</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.5.201910111838</span></div></body></html>